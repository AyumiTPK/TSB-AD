{
  "best_metric": 1.9472343921661377,
  "best_model_checkpoint": "ttm_finetuned_models/PSM2/output/checkpoint-772",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 772,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 1.7102209329605103,
      "learning_rate": 5.049637525562044e-05,
      "loss": 0.3236,
      "step": 193
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.9566293954849243,
      "eval_runtime": 9.8393,
      "eval_samples_per_second": 193.612,
      "eval_steps_per_second": 3.049,
      "step": 193
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.9186614155769348,
      "learning_rate": 8.152644313286965e-05,
      "loss": 0.3048,
      "step": 386
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.0187366008758545,
      "eval_runtime": 9.6686,
      "eval_samples_per_second": 197.03,
      "eval_steps_per_second": 3.103,
      "step": 386
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7807928919792175,
      "learning_rate": 0.00013173310681238563,
      "loss": 0.2953,
      "step": 579
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.029958963394165,
      "eval_runtime": 9.9509,
      "eval_samples_per_second": 191.439,
      "eval_steps_per_second": 3.015,
      "step": 579
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.169754981994629,
      "learning_rate": 0.00019892058303453103,
      "loss": 0.2871,
      "step": 772
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.9472343921661377,
      "eval_runtime": 9.6326,
      "eval_samples_per_second": 197.766,
      "eval_steps_per_second": 3.114,
      "step": 772
    }
  ],
  "logging_steps": 500,
  "max_steps": 9650,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "total_flos": 3041314504704000.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
